{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isai/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "import math\n",
    "import autograd.numpy as np\n",
    "import autograd\n",
    "\n",
    "# randomnize two numpy arrays\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load cifar-10-small and project down\n",
    " \n",
    "def unpickle( file ):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    " \n",
    "data = unpickle( './../Dataset/cifar-10-batches-py/data_batch_1' )\n",
    " \n",
    "X_matrix = data['data']\n",
    "t_vector = data['labels']\n",
    "t_vector = np.atleast_2d(t_vector).T\n",
    " \n",
    "N = 1000\n",
    "D = 10\n",
    "\n",
    "ROWS_AXIS = 0\n",
    "COLS_AXIS = 1\n",
    " \n",
    "# only keep N items\n",
    "X_matrix = X_matrix[ 0:N, : ] \n",
    "t_vector = t_vector[ 0:N, : ]\n",
    " \n",
    "# project down into a D-dimensional space\n",
    "X_matrix = np.dot( X_matrix, np.random.randn( 3072, D) )\n",
    " \n",
    "# whiten our data - zero mean and unit standard deviation\n",
    "X_matrix = (X_matrix - np.mean(X_matrix, axis=0)) / np.std(X_matrix, axis=0)\n",
    "\n",
    "# Adding bias\n",
    "data = pd.DataFrame(X_matrix)\n",
    "data.insert(0, \"BIAS\", np.ones(len(data)))\n",
    "X_matrix = data.values\n",
    "\n",
    "# Defining some constants\n",
    "DATASET_LENGTH = X_matrix.shape[0] # rows\n",
    "FEATURES_LENGTH = X_matrix.shape[1] # columns\n",
    "CLASSES_LENGTH = 10\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 1000\n",
    "\n",
    "# Initializing Weight matrix\n",
    "W_matrix = np.random.randn(FEATURES_LENGTH, CLASSES_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting section\n",
    "\n",
    "# x and y coordinates to plot \n",
    "x_coordinates = np.linspace(0, EPOCHS, num=EPOCHS)\n",
    "loss_y_coordinates = np.zeros(EPOCHS)\n",
    "accuracy_y_coordinates = np.zeros(EPOCHS)\n",
    "\n",
    "\n",
    "def plot(x, y, limits, title, x_label_name, y_label_name):\n",
    "    plt.close(\"all\")\n",
    "    figure = plt.figure()\n",
    "    figure.clf()\n",
    "    \n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    #plt.axis(limits)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.xlabel(x_label_name)\n",
    "\n",
    "    figure.suptitle(title, fontsize=20)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_loss():\n",
    "    limits = [0,EPOCHS,0,5]\n",
    "    plot(x_coordinates, loss_y_coordinates, limits, \"Loss Overtime\", \"Epochs\", \"Loss\")  \n",
    "    return\n",
    "    \n",
    "    \n",
    "def plot_accuracy():\n",
    "    limits = [0,EPOCHS,0,1]\n",
    "    plot(x_coordinates, accuracy_y_coordinates, limits, \"Accuracy Overtime\", \"Epochs\", \"Accuracy\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_matris is the feature matrix 1000 images by 11 features. 10 features + bias\n",
    "# W_matrix is the weigth matrix 11 features by 10 classes\n",
    "# S_matrix is the score matrix 1000 images by 10 classes\n",
    "def scores(X_matrix, W_matrix):\n",
    "    S_matrix = np.dot(X_matrix, W_matrix)\n",
    "    return S_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# S_matrix is the score matrix 1000 images by 10 classes\n",
    "# E_matrix is the exp score matrix 1000 images by 10 classes\n",
    "# P_matrix is the probability matrix 1000 images by 10 classes. Every row adds to 1\n",
    "def softmax(S_matrix): \n",
    "    # Exp-normalize trick to avoid numerical overflow\n",
    "    S_matrix = S_matrix - np.max(S_matrix) \n",
    "    \n",
    "    E_matrix = np.exp(S_matrix)\n",
    "    P_matrix = E_matrix / np.sum(E_matrix, axis=COLS_AXIS, keepdims=True) \n",
    "    return P_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# P_matrix is the probability matrix 1000 images by 10 classes. Every row adds to 1\n",
    "# L_matrix is the loss matrix 1000 images by 10 classes\n",
    "def cross_entropy(P_matrix):\n",
    "    L_matrix = -np.log(P_matrix)  \n",
    "    return L_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# L_matrix is the loss matrix 1000 images by 10 classes\n",
    "# t_vector is the target vector 1000 images by 1 label\n",
    "# l_vector is the vector that holds the loss quantities of the right classes 1000 images by 1 loss\n",
    "# l_scalar is the overall loss. It is the mean of the l_vector\n",
    "def loss(L_matrix, t_vector):\n",
    "    ROWS = np.array(DATASET_LENGTH-1)\n",
    "    COLS = t_vector\n",
    "    l_vector = L_matrix[ROWS, COLS] # this is just grabbing the correct classes to make a vector \n",
    "    l_scalar = np.mean(l_vector) \n",
    "    return l_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function receives the weights matrix and outputs the\n",
    "# overall loss of this weigths matrix\n",
    "def loss_function(W_matrix):\n",
    "    S_matrix = scores(X_matrix, W_matrix)\n",
    "    P_matrix = softmax(S_matrix)\n",
    "    L_matrix = cross_entropy(P_matrix)\n",
    "    l_scalar = loss(L_matrix, t_vector)\n",
    "    return l_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S_matrix is the score matrix 1000 images by 10 classes\n",
    "# t_vector is the target vector 1000 images by 1 label\n",
    "# p_vector is the predicted vector 1000 images by 1 prediction\n",
    "# a_vector is the accuracy vector 1000 images by 1 match\n",
    "# a_scalar is the mean of the accuracy vector\n",
    "def accuracy(S_matrix, t_vector):\n",
    "    p_vector = np.argmax(S_matrix, axis=COLS_AXIS)\n",
    "    a_vector = p_vector == t_vector\n",
    "    a_scalar = np.mean(a_vector)\n",
    "    return a_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general definition of the derivative\n",
    "# ( f(x + h) - f(x) ) / h\n",
    "#\n",
    "# In this particular implementation\n",
    "# function is the loss function\n",
    "# X_matrix is the weight matrix\n",
    "# fx_scalar is the loss for that weight matrix\n",
    "# \n",
    "# Xh_matrix is the weight vector plus h at the current row and col\n",
    "# fxh_scalar is the loss of this new weight matrix\n",
    "# G_matrix[row,col] = (fxh_scalar - fx_scalar) / h_scalar  is the partial derivative\n",
    "\n",
    "h_scalar = 0.000001\n",
    "\n",
    "def gradient(function, X_matrix):\n",
    "    # Initializing a gradient matrix\n",
    "    G_matrix = np.zeros_like(X_matrix)\n",
    "    \n",
    "    # computing f(x)\n",
    "    fx_scalar = function(X_matrix)\n",
    "    \n",
    "    # getting ready for computing partial derivatives one row-col pair at a time\n",
    "    for col in range(X_matrix.shape[COLS_AXIS]):\n",
    "        for row in range(X_matrix.shape[ROWS_AXIS]):\n",
    "            \n",
    "            # adding h to one square in the new x matrix\n",
    "            Xh_matrix = X_matrix\n",
    "            Xh_matrix[row, col] = Xh_matrix[row, col] + h_scalar\n",
    "            \n",
    "            # computing f(x+h)\n",
    "            fxh_scalar = function(Xh_matrix)\n",
    "            \n",
    "            # partial derivative is the derivative of a function  \n",
    "            # with respect to one variable, while treating the other variables as constants\n",
    "            partial_derivative = (fxh_scalar - fx_scalar) / h_scalar \n",
    "            \n",
    "            # saving this partial derivative in it corresponding place of the\n",
    "            # gradient matrix\n",
    "            G_matrix[row, col] = partial_derivative\n",
    "        \n",
    "    return G_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning section\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Shuffling features and labels to help learning\n",
    "    #X_matrix, t_vector = shuffle(X_matrix, t_vector, random_state=0)\n",
    "    \n",
    "    # Feed forward phase\n",
    "    S_matrix = scores(X_matrix, W_matrix)\n",
    "    P_matrix = softmax(S_matrix)\n",
    "    L_matrix = cross_entropy(P_matrix)\n",
    "    \n",
    "    # Getting numbers for plotting\n",
    "    l_scalar = loss(L_matrix, t_vector)\n",
    "    a_scalar = accuracy(P_matrix, t_vector)\n",
    "    \n",
    "    # Getting gradient and updating weigths \n",
    "    G_matrix = gradient(loss_function, W_matrix)\n",
    "    W_matrix = W_matrix - ( LEARNING_RATE * G_matrix )\n",
    "    \n",
    "    # Updating y coordinates for plotting\n",
    "    loss_y_coordinates[epoch] = l_scalar\n",
    "    accuracy_y_coordinates[epoch] = a_scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
