{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isai/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "STEPS_SIZE = 10\n",
    "\n",
    "GRAPH_STEPS = EPOCHS / STEPS_SIZE\n",
    "\n",
    "# x and y coordinates to plot \n",
    "x_coordinates = np.linspace(0, GRAPH_STEPS, num=GRAPH_STEPS)\n",
    "loss_y_coordinates = np.zeros(GRAPH_STEPS)\n",
    "accuracy_y_coordinates = np.zeros(GRAPH_STEPS)\n",
    "\n",
    "def plot(x, y, limits, title, x_label_name, y_label_name):\n",
    "    plt.close(\"all\")\n",
    "    figure = plt.figure()\n",
    "    figure.clf()\n",
    "    \n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    #plt.axis(limits)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.xlabel(x_label_name)\n",
    "\n",
    "    figure.suptitle(title, fontsize=20)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_loss():\n",
    "    limits = [0,GRAPH_STEPS,0,5]\n",
    "    plot(x_coordinates, loss_y_coordinates, limits, \"Loss Overtime\", \"Epochs\", \"Loss\")  \n",
    "    return\n",
    "\n",
    "def plot_accuracy():\n",
    "    limits = [0,GRAPH_STEPS,0,1]\n",
    "    plot(x_coordinates, accuracy_y_coordinates, limits, \"Accuracy Overtime\", \"Epochs\", \"Accuracy\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape,name):\n",
    "    gaussian_matrix = tf.truncated_normal(shape, stddev=0.1)\n",
    "    weight_matrix = tf.Variable(gaussian_matrix, name=name)\n",
    "    return weight_matrix\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "    gaussian_vector = tf.truncated_normal(shape, stddev=0.1)\n",
    "    bias_vector = tf.Variable(gaussian_vector, name=name)\n",
    "    return bias_vector\n",
    "\n",
    "def convolution(images_matrix, weight_matrix):\n",
    "    # [batch, height, width, depth]\n",
    "    strides = [1,2,2,1]\n",
    "    convoluted_images_matrix = tf.nn.conv2d(images_matrix, weight_matrix, strides=strides, padding='SAME')\n",
    "    return convoluted_images_matrix\n",
    "\n",
    "def max_pool_2x2(images_matrix):\n",
    "    # [batch, height, width, depth]\n",
    "    strides = [1,2,2,1]\n",
    "    ksize = [1,2,2,1] #[1,2,2,1]\n",
    "    smaller_images_matrix = tf.nn.max_pool(images_matrix, ksize=ksize, strides=strides, padding='SAME')\n",
    "    return smaller_images_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs') as scope:\n",
    "    # inputs\n",
    "    features_matrix = tf.placeholder(tf.float32, shape=(None, 784), name='features_matrix')\n",
    "    targets_matrix = tf.placeholder(tf.float32, shape=[None, 10], name=\"targets_matrix\")\n",
    "\n",
    "    # reshaping images as grids instead of vectors for convolution\n",
    "    images_matrix = tf.reshape(features_matrix, [-1,28,28,1], name=\"images_matrix\")\n",
    "    \n",
    "\n",
    "with tf.name_scope('convolutional1') as scope:\n",
    "    # hidden inputs\n",
    "    weight_matrix_conv1 = weight_variable([5, 5, 1, 32],name=\"weight_matrix_conv1\")\n",
    "    bias_vector_conv1 = bias_variable([32], name=\"bias_vector_conv1\")\n",
    "    \n",
    "    # linear operation\n",
    "    linear_convoluted_matrix_conv1 = convolution(images_matrix, weight_matrix_conv1) + bias_vector_conv1\n",
    "    \n",
    "    # nonlinear operation\n",
    "    nonlinear_convoluted_matrix_conv1 = tf.nn.relu(linear_convoluted_matrix_conv1)\n",
    "    \n",
    "    # making output smaller\n",
    "    smaller_matrix_conv1 = max_pool_2x2(nonlinear_convoluted_matrix_conv1)\n",
    "    \n",
    "    \n",
    "with tf.name_scope('convolutional2') as scope:\n",
    "    # hidden inputs\n",
    "    weight_matrix_conv2 = weight_variable([5, 5, 32, 64], name=\"weight_matrix_conv2\")\n",
    "    bias_vector_conv2 = bias_variable([64], name=\"bias_vector_conv2\")\n",
    "    \n",
    "    # linear operation\n",
    "    linear_convoluted_matrix_conv2 = convolution(smaller_matrix_conv1, weight_matrix_conv2) + bias_vector_conv2\n",
    "    \n",
    "    # nonlinear operation\n",
    "    nonlinear_convoluted_matrix_conv2 = tf.nn.relu(linear_convoluted_matrix_conv2)\n",
    "    \n",
    "    # making output smaller\n",
    "    smaller_matrix_conv2 = max_pool_2x2(nonlinear_convoluted_matrix_conv2)\n",
    "    \n",
    "    # making output flat for fully connected layer\n",
    "    smaller_matrix_conv2_flat = tf.reshape(smaller_matrix_conv2, [-1, 2*2*64])\n",
    "\n",
    "    \n",
    "with tf.name_scope('fully_connected_hidden1') as scope:\n",
    "    # hidden inputs\n",
    "    weight_matrix_fc1 = weight_variable([2 * 2 * 64, 1024], name=\"weight_matrix_fc1\")\n",
    "    bias_vector_fc1 = bias_variable([1024], name=\"bias_vector_fc1\")\n",
    "    \n",
    "    # linear operation\n",
    "    linear_hidden_matrix_fc1 = tf.matmul(smaller_matrix_conv2_flat, weight_matrix_fc1) + bias_vector_fc1\n",
    "    \n",
    "    # nonlinear operation\n",
    "    nonlinear_hidden_matrix_fc1 = tf.nn.relu(linear_hidden_matrix_fc1)\n",
    "\n",
    "    \n",
    "with tf.name_scope('fully_connected_output') as scope:\n",
    "    # hidden inputs\n",
    "    weight_matrix_fc2 = weight_variable([1024, 10], name=\"weight_matrix_fc2\")\n",
    "    bias_vector_fc2 = bias_variable([10], name=\"bias_vector_fc2\")\n",
    "    \n",
    "    # linear operation\n",
    "    output_matrix_fc2 = tf.matmul(nonlinear_hidden_matrix_fc1, weight_matrix_fc2) + bias_vector_fc2\n",
    "    \n",
    "    # making output probabilities\n",
    "    probabilities_matrix = tf.nn.softmax(output_matrix_fc2)\n",
    "    \n",
    "    \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(targets_matrix * tf.log(probabilities_matrix), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(probabilities_matrix,1), tf.argmax(targets_matrix,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    merged_summary_op = tf.merge_all_summaries()\n",
    "    summary_writer = tf.train.SummaryWriter('./ConvNet_TensorBoard',graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(EPOCHS):\\n    batch = mnist.train.next_batch(50)\\n    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\\n    if epoch % STEPS_SIZE == 0:\\n        #features_test, targets_test = mnist.test.images, mnist.test.labels\\n        #l_scalar = sess.run(cross_entropy, feed_dict={x:batch[0], y_: batch[1]})\\n        #a_scalar = sess.run(accuracy, feed_dict={x:batch[0], y_: batch[1]})\\n        l_scalar = sess.run(cross_entropy, feed_dict={x:batch[0], y_: batch[1]})\\n        a_scalar = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\\n        \\n        \\n        loss_y_coordinates[epoch] = l_scalar\\n        accuracy_y_coordinates[epoch] = a_scalar\\n    \\n    \\n\\n    print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for epoch in range(EPOCHS):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    if epoch % STEPS_SIZE == 0:\n",
    "        #features_test, targets_test = mnist.test.images, mnist.test.labels\n",
    "        #l_scalar = sess.run(cross_entropy, feed_dict={x:batch[0], y_: batch[1]})\n",
    "        #a_scalar = sess.run(accuracy, feed_dict={x:batch[0], y_: batch[1]})\n",
    "        l_scalar = sess.run(cross_entropy, feed_dict={x:batch[0], y_: batch[1]})\n",
    "        a_scalar = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        \n",
    "        \n",
    "        loss_y_coordinates[epoch] = l_scalar\n",
    "        accuracy_y_coordinates[epoch] = a_scalar\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
